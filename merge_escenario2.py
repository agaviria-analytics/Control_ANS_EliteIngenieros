"""
------------------------------------------------------------
ESCENARIO 2 - MERGE CONSOLIDADO (HV / PUNTOS / PREPAGO)
------------------------------------------------------------
Autor: H√©ctor + IA (2025)
------------------------------------------------------------
"""

import pandas as pd
from pathlib import Path
import re
import numpy as np
from tkinter import Tk, messagebox

# ------------------------------------------------------------
# 1Ô∏è‚É£ CONFIGURACI√ìN INICIAL
# ------------------------------------------------------------
base_path = Path("data_clean")

archivos = {
    "HV": base_path / "HV_limpio.xlsx",
    "PUNTOS": base_path / "PUNTOS_limpio.xlsx",
    "PREPAGO": base_path / "PREPAGO_limpio.xlsx"
}

datasets = []

# ------------------------------------------------------------
# AVISO INFORMATIVO (no elimina filas, solo notifica)
# ------------------------------------------------------------
root = Tk()
root.withdraw()  # Oculta la ventana principal
messagebox.showinfo(
    "Control ANS ‚Äì MERGE CONSOLIDADO",
    "El sistema conservar√° todos los registros.\n\n"
    "Los valores vac√≠os ser√°n reemplazados por indicadores visibles:\n"
    "‚Ä¢ 'SIN_PEDIDO' en pedidos vac√≠os\n"
    "‚Ä¢ 'SIN DATO' en texto\n"
    "‚Ä¢ '1900-01-01' en fechas\n"
    "‚Ä¢ 0 en n√∫meros\n\n"
    "Recuerda cerrar Excel antes de continuar."
)
root.destroy()


# ------------------------------------------------------------
# 2Ô∏è‚É£ CARGA Y LIMPIEZA DE CADA ARCHIVO
# ------------------------------------------------------------
# ------------------------------------------------------------
# 2Ô∏è‚É£ CARGA Y LIMPIEZA DE CADA ARCHIVO (CON VALIDACI√ìN ESTRUCTURAL)
# ------------------------------------------------------------
diagnostico_path = base_path / "Diagnostico_Estructura.txt"
with open(diagnostico_path, "w", encoding="utf-8") as log:
    log.write("------------------------------------------------------------\n")
    log.write("üìã DIAGN√ìSTICO DE ESTRUCTURA DE ARCHIVOS LIMPIOS - MERGE ANS\n")
    log.write("------------------------------------------------------------\n")

columnas_requeridas = [
    "PEDIDO", "MUNICIPIO", "FECHA_INGRESO", "FECHA_INICIO_ANS",
    "ZONA", "SECTOR", "DIAS_CUMP", "FECHA_LIMITE",
    "DIAS_TRANSCURRIDOS", "DIAS_RESTANTES", "ESTADO"
]

for nombre, ruta in archivos.items():
    if ruta.exists():
        df = pd.read_excel(ruta)

        # üîπ Registrar estructura detectada
        with open(diagnostico_path, "a", encoding="utf-8") as log:
            log.write(f"\nüóÇÔ∏è Archivo: {ruta.name}\n")
            log.write(f"Total columnas detectadas: {len(df.columns)}\n")
            for col in df.columns:
                log.write(f"   - {col}\n")

        # üîπ Normalizar encabezados
        df.columns = df.columns.str.strip().str.upper()

        # üîπ Validar columnas requeridas
        faltantes = [col for col in columnas_requeridas if col not in df.columns]
        if faltantes:
            mensaje = (
                f"‚ùå ERROR: Faltan columnas obligatorias en el archivo {ruta.name}.\n\n"
                f"Columnas faltantes: {', '.join(faltantes)}\n\n"
                f"Revisa el formato antes de continuar.\n"
                f"El proceso se detuvo para evitar errores en Power BI."
            )
            print(mensaje)
            root = Tk()
            root.withdraw()
            messagebox.showerror("Error de estructura", mensaje)
            root.destroy()
            raise SystemExit("‚ùå Estructura inv√°lida. Proceso detenido.")

        # üîπ Eliminar columna duplicada "PEDIDO" si existe m√°s de una
        columnas_pedido = [c for c in df.columns if "PEDIDO" in c]
        if len(columnas_pedido) > 1:
            print(f"‚ö†Ô∏è {nombre}: se detect√≥ columna PEDIDO duplicada, se eliminar√° la segunda.")
            df = df.loc[:, ~df.columns.duplicated()]
            df = df.loc[:, ~df.columns.str.contains("PEDIDO.1", regex=True)]

        # üîπ Asegurar columnas consistentes
        for col in columnas_requeridas:
            if col not in df.columns:
                df[col] = pd.NA

        # üîπ Reordenar y agregar tipo
        df = df[columnas_requeridas]
        df["TIPO_DATASET"] = nombre

        datasets.append(df)
        print(f"‚úÖ {nombre} cargado correctamente ({len(df)} registros)")
    else:
        print(f"‚ö†Ô∏è No se encontr√≥ el archivo: {ruta}")

with open(diagnostico_path, "a", encoding="utf-8") as log:
    log.write("\n‚úÖ Validaci√≥n completada. No se detectaron errores estructurales.\n")
# ------------------------------------------------------------
# 3Ô∏è‚É£ MERGE FINAL ORIGINAL
# ------------------------------------------------------------
if not datasets:
    raise SystemExit("‚ùå No se encontr√≥ ning√∫n archivo limpio para consolidar.")

consolidado = pd.concat(datasets, ignore_index=True)
print(f"\nüîπ Registros combinados totales: {len(consolidado)}")

# ‚ö†Ô∏è NO eliminar vac√≠os ni duplicados aqu√≠ (archivo original)
salida_total = base_path / "MERGE_ANS.xlsx"
consolidado.to_excel(salida_total, index=False)
print(f"\nüì¶ Archivo consolidado original generado (intacto): {salida_total}")

# ------------------------------------------------------------
# 4Ô∏è‚É£ LIMPIEZA Y NORMALIZACI√ìN DE TEXTO (FINAL)
# ------------------------------------------------------------
for col in ["MUNICIPIO", "SECTOR", "ESTADO"]:
    consolidado[col] = (
        consolidado[col]
        .astype(str)
        .str.upper()
        .str.strip()
        .str.replace(r"‚Äì", "-", regex=True)
        .str.replace(r"\s+", " ", regex=True)
        .str.replace(r"√Å", "A", regex=True)
        .str.replace(r"√â", "E", regex=True)
        .str.replace(r"√ç", "I", regex=True)
        .str.replace(r"√ì", "O", regex=True)
        .str.replace(r"√ö", "U", regex=True)
    )

# üîπ LIMPIEZA DE SECTOR
reemplazos_sector = {
    "OCCIDENETE": "OCCIDENTE",
    "OCCIDENTE - OLAYA": "OCCIDENTE",
    "OCCIDENTE - SAN CRISTOBAL": "OCCIDENTE",
    "OCCIDENTE ‚Äì AGUAS FRIAS": "OCCIDENTE",
    "OCCIDENTE-AGUAS FRIAS": "OCCIDENTE",
    "SUR - SABANETA": "SUR",
    "SUR - AGIZAL": "SUR",
    "SUR-S.PRADO": "SUR",
    "SUR-SABANETA": "SUR",
    "SUR ITAGUI AGIZAL": "SUR",
    "SUR-LIMONAR": "SUR",
    "ENV": "SUR",
    "REPL": np.nan,
    "NORTE": np.nan
}
consolidado["SECTOR"] = consolidado["SECTOR"].replace(reemplazos_sector)

def limpiar_sector(valor):
    if pd.isna(valor):
        return np.nan
    if re.match(r"^OCCIDENTE", valor):
        return "OCCIDENTE"
    elif re.match(r"^SUR", valor):
        return "SUR"
    elif re.match(r"^ORIENTE", valor):
        return "ORIENTE"
    elif re.match(r"^LA ESTRELLA", valor):
        return "SUR"
    else:
        return valor

consolidado["SECTOR"] = consolidado["SECTOR"].apply(limpiar_sector)
consolidado["SECTOR"] = consolidado["SECTOR"].replace(["NAN", "NONE", "NULL", "PD.NA", "SIN DATO"], np.nan)

# üîπ LIMPIEZA DE MUNICIPIO
reemplazos_municipio = {
    "MED": "MEDELLIN",
    "MEDLLIN": "MEDELLIN",
    "ENVIG": "ENVIGADO",
    "ENV": "ENVIGADO",
    "SAB": "SABANETA",
    "LA ESTRELLA": "LA ESTRELLA",
    "CAL": "CALDAS",
    "GUAR": "GUARNE",
    "ESTR": "LA ESTRELLA",
    "EL RET": "EL RETIRO",
    "ENVI": "ENVIGADO"
}
consolidado["MUNICIPIO"] = consolidado["MUNICIPIO"].replace(reemplazos_municipio)

# üîπ LIMPIEZA DE ESTADO
reemplazos_estado = {
    "VENC": "VENCIDO",
    "VENCID": "VENCIDO",
    "CUMP": "CUMPLIDO",
    "ALER": "ALERTA",
    "SINFECHA": "SIN FECHA",
    "SIN FECHAS": "SIN FECHA"
}
consolidado["ESTADO"] = consolidado["ESTADO"].replace(reemplazos_estado)

# ------------------------------------------------------------
# 5Ô∏è‚É£ DIAGN√ìSTICO DE CALIDAD
# ------------------------------------------------------------
print("\nüìä Diagn√≥stico de valores √∫nicos despu√©s de limpieza:")
print("SECTOR     ‚Üí", consolidado["SECTOR"].dropna().unique())
print("MUNICIPIO  ‚Üí", consolidado["MUNICIPIO"].dropna().unique()[:10])
print("ESTADO     ‚Üí", consolidado["ESTADO"].dropna().unique())

print("\nüìà Conteo por SECTOR y ESTADO:")
print(consolidado.groupby(["SECTOR", "ESTADO"]).size())

# ------------------------------------------------------------
# 6Ô∏è‚É£ MERGE PARA POWER BI (CONSERVA TODO Y RELLENA VAC√çOS)
# ------------------------------------------------------------
print("\nüîç Preparando MERGE_ANS_FINAL con valores visibles para an√°lisis en Power BI...")

merge_para_powerbi = consolidado.copy()

# üîπ Reemplazar valores vac√≠os por indicadores visibles
# üîπ Reemplazar valores vac√≠os por indicadores visibles
for col in merge_para_powerbi.columns:
    # üî∏ Primero, limpiar espacios y valores tipo "nan", "None", etc.
    merge_para_powerbi[col] = merge_para_powerbi[col].replace(
        ["", " ", "NaN", "NAN", "None", None, np.nan], pd.NA
    )

    # üî∏ Ahora aplicar los reemplazos seg√∫n tipo de dato
    if col == "PEDIDO":
        merge_para_powerbi[col] = merge_para_powerbi[col].fillna("SIN_PEDIDO")
    elif merge_para_powerbi[col].dtype in ["float64", "int64"]:
        merge_para_powerbi[col] = merge_para_powerbi[col].fillna(0)
    elif "FECHA" in col:
        merge_para_powerbi[col] = merge_para_powerbi[col].fillna("1900-01-01")
    else:
        merge_para_powerbi[col] = merge_para_powerbi[col].fillna("SIN DATO")

# üîπ Crear hoja resumen de vac√≠os originales (antes del reemplazo)
vacios_por_columna = consolidado.isna().sum()
porcentaje_vacios = (vacios_por_columna / len(consolidado) * 100).round(2)

df_alerta = pd.DataFrame({
    "Columna": vacios_por_columna.index,
    "Valores_Vac√≠os": vacios_por_columna.values,
    "Porcentaje (%)": porcentaje_vacios.values
}).sort_values(by="Valores_Vac√≠os", ascending=False)

# üîπ Generar hoja con resumen general
df_resumen = pd.DataFrame({
    "M√©trica": [
        "Total de registros",
        "Filas duplicadas",
        "Filas completamente vac√≠as"
    ],
    "Valor": [
        len(consolidado),
        consolidado.duplicated().sum(),
        consolidado.isna().all(axis=1).sum()
    ]
})
# üîπ Guardar en un solo archivo Excel con m√∫ltiples hojas
salida_powerbi = base_path / "MERGE_ANS_FINAL.xlsx"

# üü¢ Aviso preventivo antes de exportar
from tkinter import messagebox
messagebox.showinfo(
    "Control ANS - MERGE CONSOLIDADO",
    "Antes de continuar, aseg√∫rate de que el archivo MERGE_ANS_FINAL.xlsx est√© cerrado.\n\n"
    "Esto evitar√° errores de permiso durante la exportaci√≥n."
)

try:
    with pd.ExcelWriter(salida_powerbi, engine="openpyxl") as writer:
        merge_para_powerbi.to_excel(writer, sheet_name="MERGE_ANS_FINAL", index=False)
        df_resumen.to_excel(writer, sheet_name="Resumen_General", index=False)
        df_alerta.to_excel(writer, sheet_name="ALERTA_DATOS_VACIOS", index=False)

    print(f"üìÅ Archivo listo para Power BI: {salida_powerbi}")
    print(f"üìä Incluye hojas 'MERGE_ANS_FINAL', 'Resumen_General' y 'ALERTA_DATOS_VACIOS'.")
    print("‚úÖ Todos los vac√≠os fueron reemplazados con valores visibles (SIN DATO, 0, 1900-01-01).")

except PermissionError:
    messagebox.showerror(
        "Error de Permiso",
        "No se pudo generar el archivo MERGE_ANS_FINAL.xlsx.\n\n"
        "Causa: El archivo est√° abierto en Excel o Power BI.\n\n"
        "Cierra el archivo y vuelve a ejecutar el proceso."
    )
    print("‚ùå Error: El archivo MERGE_ANS_FINAL.xlsx est√° abierto. Cierra Excel y vuelve a ejecutar.")

# ------------------------------------------------------------
# 7Ô∏è‚É£ (OPCIONAL) ARCHIVOS SEPARADOS POR TIPO
# ------------------------------------------------------------
for tipo in consolidado["TIPO_DATASET"].unique():
    df_tipo = consolidado[consolidado["TIPO_DATASET"] == tipo]
    salida_tipo = base_path / f"{tipo}_filtrado.xlsx"
    df_tipo.to_excel(salida_tipo, index=False)
    print(f"üóÇÔ∏è Archivo separado generado: {salida_tipo}")

print("\n‚úÖ Consolidaci√≥n completada con √©xito y datos estandarizados.")
